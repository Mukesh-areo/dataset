inimport argparse
from PyPDF2 import PdfFileWriter, PdfFileReader
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.lib.units import inch

def add_logo_to_pdf(input_folder, output_folder, logo_path):
    # Path to the PDF file
    input_pdf_path = input_folder + '/input.pdf'
    output_pdf_path = output_folder + '/output.pdf'

    # Create a canvas for the logo
    c = canvas.Canvas('logo.pdf', pagesize=letter)
    c.drawImage(logo_path, 0, 0, width=1*inch, height=1*inch)
    c.save()

    # Read the PDF file
    input_pdf = PdfFileReader(open(input_pdf_path, 'rb'))
    output_pdf = PdfFileWriter()

    # Open the logo PDF file
    logo_pdf = PdfFileReader(open('logo.pdf', 'rb'))

    # Get the first page of the logo PDF
    logo_page = logo_pdf.getPage(0)

    # Iterate over each page in the input PDF file
    for i in range(input_pdf.getNumPages()):
        # Get the page from the input PDF
        page = input_pdf.getPage(i)
        
        # Create a new page with the same dimensions as the input page
        new_page = page.createBlankPage(width=int(page.mediaBox.getWidth()), height=int(page.mediaBox.getHeight()))

        # Add the logo to the new page's header
        new_page.mergeTranslatedPage(logo_page, 0, int(page.mediaBox.getHeight()) - int(1*inch))

        # Add the logo to the new page's footer
        new_page.mergeTranslatedPage(logo_page, 0, 1*inch)

        # Add the original page's content to the new page
        new_page.mergeTranslatedPage(page, 0, 0)

        # Add the new page to the output PDF
        output_pdf.addPage(new_page)

    # Write the output PDF to a file
    with open(output_pdf_path, 'wb') as f:
        output_pdf.write(f)

if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Add logo to PDF header and footer.')
    parser.add_argument('input_folder', help='Path to the input folder containing the PDF file.')
    parser.add_argument('output_folder', help='Path to the output folder where the modified PDF will be saved.')
    parser.add_argument('logo_path', help='Path to the logo image.')
    args = parser.parse_args()

    # Call the function with parsed arguments
    add_logo_to_pdf(args.input_folder, args.output_folder, args.logo_path)






# my_script.spec

block_cipher = None

a = Analysis(['my_script.py'],
             pathex=['C:\\path\\to\\your\\script'],
             binaries=[],
             datas=[],
             hiddenimports=[],
             hookspath=[],
             runtime_hooks=[],
             excludes=[],
             win_no_prefer_redirects=False,
             win_private_assemblies=False,
             cipher=block_cipher,
             noarchive=False)

pyz = PYZ(a.pure, a.zipped_data,
             cipher=block_cipher)

exe = EXE(pyz,
          a.scripts,
          [],
          exclude_binaries=True,
          name='my_script',
          debug=False,
          bootloader_ignore_signals=False,
          strip=False,
          upx=True,
          console=False )
import streamlit as st

# List of text to highlight
text_list = ["This is text 1", "This is text 2", "This is text 3"]

# Define colors for highlighting
colors = ["red", "blue", "green"]

# Display each text in the list with a different color
for i, text in enumerate(text_list):
    st.markdown(f'<span style="color:{colors[i]}">{text}</span>', unsafe_allow_html=True)








import streamlit as st
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Streamlit app title and description
st.title('HTML Content Highlighter')
st.write('This app highlights the main <div> tag in an HTML file that contains similar content.')

# Function to highlight the main div containing the matched content
def highlight_main_div(html_content, contents):
    # Create a TF-IDF vectorizer
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(contents)

    # Calculate cosine similarity between each pair of contents
    similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # Find and highlight the main div surrounding the matching content in the HTML
    for i in range(len(contents)):
        for j in range(i+1, len(contents)):
            similarity = similarities[i][j]
            if similarity > 0.80:
                # Search for content i and j in the HTML content
                if re.search(re.escape(contents[i]) + '|' + re.escape(contents[j]), html_content):
                    # Add the background color to the main div containing the content
                    pattern = re.compile(rf'<div>(?=.*?{re.escape(contents[i])})(?=.*?{re.escape(contents[j])}).*?</div>', re.DOTALL)
                    html_content = re.sub(pattern, rf'<div style="background-color: yellow;">\g<0></div>', html_content)
    return html_content

# Streamlit file uploader for input HTML file
uploaded_file = st.file_uploader("Upload an HTML file", type=["html"])

if uploaded_file is not None:
    # Read the uploaded file
    html_content = uploaded_file.getvalue().decode('utf-8')

    # Example list of contents
    contents = [
        "The application downloads files from http://techslides.com and http://download.blender.org. If these domains are not accessible it will not work. You can change the source location of files to download by changing the contents of url1 and url2 variables in main.js file.",
        "A model trained for text generation can be later adapted to follow instructions. One of the most used open-source models for instruction is OpenAssistant, which you can try at Hugging Chat."
    ]

    # Highlight the main div containing the matched content
    highlighted_content = highlight_main_div(html_content, contents)

    # Streamlit link to download the output HTML file
    st.markdown(get_binary_file_downloader_html(highlighted_content, file_name="highlighted_content.html"), unsafe_allow_html=True)





import streamlit as st
import re

# Streamlit app title and description
st.title('HTML Content Extractor')
st.write('This app extracts content from an HTML file using a specified regex pattern.')

# Streamlit file uploader for input HTML file
uploaded_file = st.file_uploader("Upload an HTML file", type=["html"])

# Streamlit text input for regex pattern
regex_pattern = st.text_input("Enter the regex pattern")

if uploaded_file is not None:
    # Read the uploaded file
    html_content = uploaded_file.getvalue().decode('utf-8')

    # Find all matches using the specified pattern
    matches = re.findall(regex_pattern, html_content, re.DOTALL)

    # Store the matches in a list
    content_list = []
    for match in matches:
        content_list.append(match.strip())

    # Display the extracted content
    st.write("Extracted Content:")
    for content in content_list:
        st.write(content)

